{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870e9ff9-ef4c-4981-8f54-3db51385eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1  col_2  col_3\n",
      "row_0      0      1      2      3\n",
      "row_1      4      5      6      7\n",
      "row_2      8      9     10     11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
    "                  columns=['col_0', 'col_1', 'col_2', 'col_3'],\n",
    "                  index=['row_0', 'row_1', 'row_2'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec80a48-c1a5-47ad-a512-041c371658d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "w\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "a=[1, 1, 1]\n",
    "for i in range(len(a)):\n",
    "    print(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58c9c9d1-424f-4ae3-a7dd-739f10574645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240130_0943\n",
      "(70,)\n",
      "(70,)\n",
      "1\n",
      "Model in Epoch 60\n",
      "TestLoss: 3.9867 TestAcc: 0.3857\n",
      "[[ 9  0  3  8]\n",
      " [ 5  1  1  4]\n",
      " [ 9  0  3  8]\n",
      " [ 3  1  1 14]]\n",
      " \n",
      "         CLASS\n",
      "s1.png       0\n",
      "s10.png      2\n",
      "s11.png      3\n",
      "s12.png      0\n",
      "s13.png      3\n",
      "...        ...\n",
      "30.png       3\n",
      "4.png        2\n",
      "6.png        3\n",
      "8.png        3\n",
      "9.png        3\n",
      "\n",
      "[70 rows x 1 columns]\n",
      "CSV saved in  C:\\Users\\AKIZUKI\\JupyterProjects\\AerialPhoto_Forwarded\\20240301ishikawa\\20240130_0943_ep60.csv\n",
      "Forwarding Complete!!!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "date=20240130\n",
    "time=\"0943\"\n",
    "filedate=str(date)+\"_\"+str(time)\n",
    "print(filedate)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "Channels=4\n",
    "IMG_SIZE=224\n",
    "target_epoch=60\n",
    "\n",
    "Classes = [\"higainashi\", \"houdo\", \"kanbotsu\", \"rokatahoukai\"]\n",
    "ClassNum = len(Classes)\n",
    "\n",
    "testpath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\QGISedited\\test_ishikawa\"\n",
    "savepath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\AerialPhoto_savedmodel\"\n",
    "forwardpath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\AerialPhoto_Forwarded\\20240301ishikawa\"\n",
    "\n",
    "#後で画像ファイル名ごとに推測ラベルを付けるためにfilelistをここで作る\n",
    "pathlist=list(sorted(Path(testpath).glob(\"*\\*\")))\n",
    "filelist=[]\n",
    "pathlist_binary=list(sorted(Path(testpath+\"binary\").glob(\"*\\*\")))\n",
    "filelist_binary=[]\n",
    "for i in range(len(pathlist)):\n",
    "    filelist.append(str(pathlist[i]).split(\"\\\\\")[-1])\n",
    "    filelist_binary.append(str(pathlist_binary[i]).split(\"\\\\\")[-1])\n",
    "\n",
    "print(np.array(filelist).shape)\n",
    "print(np.array(filelist_binary).shape)\n",
    "\n",
    "\n",
    "'''\n",
    "PytorchではDataloaderという,膨大なデータセットからでもメモリを圧迫せずに取り出せてforループにも対応するための枠組みがある\n",
    "データセットをDataloaderが引っ張ってこれるような形式にするためにMyDataset(torch.utils.data.Dataset)というクラスを作れば，\n",
    "あとはそのメソッドをtorch.utils.data.Datasetが勝手に使用してデータを加工してくれる\n",
    "__init__, __getitem__, __len__をクラス内で必ず定義しなければならない\n",
    "Dataloader内のデータはバッチごとにまとめられる\n",
    "'''\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, data2, transforms, Classes) -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.Classes = Classes\n",
    "        #globは複数のファイルのパスをまとめて取得する\n",
    "        #訓練と訓練白黒の二個下のディレクトリから画像を取得\n",
    "        self.data = data\n",
    "        self.data2= data2\n",
    "\n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        data = self.data[index]\n",
    "        data2 = self.data2[index]\n",
    "\n",
    "        img1 = cv2.imread(str(data))\n",
    "        img1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))\n",
    "        img2_tmp = cv2.imread(str(data2))\n",
    "\n",
    "        # グレースケールに変換\n",
    "        img2_tmp = cv2.cvtColor(img2_tmp,cv2.COLOR_BGR2GRAY)\n",
    "        # 2値化\n",
    "        ret,img2 = cv2.threshold(img2_tmp, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "        img2 = cv2.resize(img2, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        #img1のテンソルとimg2のテンソルをチャンネル方向(dim0)に結合\n",
    "        cat_img = torch.cat((TF.to_tensor(img1), TF.to_tensor(img2)), dim=0)\n",
    "\n",
    "        # データの変形 (transforms)\n",
    "        transformed_img = self.transforms(cat_img)\n",
    "\n",
    "        #ラベル貼り：dataというパスを/で区切ってリストにし，クラス名のところをラベルに格納\n",
    "        #クラス名は文字列なので，self.Classesの要素と比較して一致するところの番号をラベルとする\n",
    "        label = str(data).split(\"\\\\\")[-2]\n",
    "        label = torch.tensor(self.Classes.index(label))\n",
    "\n",
    "        return transformed_img, label\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "#入力データに施す処理\n",
    "transforms = v2.Compose([\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0,0,0,0], std=[0.2, 0.2, 0.2, 0.2]),\n",
    "])\n",
    "\n",
    "testset= MyDataset(data=pathlist, data2=pathlist_binary, transforms=transforms, Classes=Classes)\n",
    "\n",
    "testloader = DataLoader(dataset=testset,batch_size=len(testset),shuffle=False)\n",
    "print(len(testloader))\n",
    "\n",
    "resnet50 = models.resnet50()\n",
    "\n",
    "resnet50.conv1 = torch.nn.Conv2d(Channels,64,kernel_size = (7,7),stride = (2,2), padding = (3,3), bias = False)\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "#modifying final layer\n",
    "resnet50.fc = nn.Linear(num_ftrs,ClassNum)\n",
    "\n",
    "#lossfunction&optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def evaluate(testloader, model, loss_fn, optimizer):\n",
    "    size_test = len(testloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_correct /= size_test\n",
    "\n",
    "    print(f'TestLoss: {test_loss:.4f} TestAcc: {test_correct:.4f}')\n",
    "\n",
    "    #ndarrayにするため、ラベルyと推測結果predをgpuからcpuへ返す\n",
    "    y=y.to(cpu)\n",
    "    pred=pred.to(cpu)\n",
    "\n",
    "    y=np.array(y)\n",
    "\n",
    "    #predは各クラスの確率になってる（onehotに近い）ので実際のクラス番号に戻す\n",
    "    pred_class=pred.argmax(1)\n",
    "    pred_class=np.array(pred_class)\n",
    "\n",
    "\n",
    "    #テストデータの混同行列を計算し可視化\n",
    "    #scikitlearnの混同行列はラベルをonehotではなく実際のクラス番号にする必要がある\n",
    "    #混同行列の見方は行が正解ラベルのクラス列が推定クラス\n",
    "    print(confusion_matrix(y, pred_class))\n",
    "    print(\" \")\n",
    "    csvpath=str(Path(forwardpath+\"\\\\\"+filedate+\"_ep\"+str(target_epoch)+\".csv\"))\n",
    "    chart=pd.DataFrame(pred_class, columns=['CLASS'], index=filelist)\n",
    "    chart.to_csv(csvpath)\n",
    "    print(chart)\n",
    "    print(\"CSV saved in \", csvpath)\n",
    "\n",
    "\n",
    "#モデル構築\n",
    "modelpath = Path(savepath+\"\\\\\"+str(target_epoch)+\"\\model_weights\"+filedate+\".pth\")\n",
    "epochmodel = resnet50\n",
    "epochmodel.load_state_dict(torch.load(modelpath))\n",
    "#GPUにニューラルネットワークを渡す\n",
    "epochmodel=epochmodel.to(device)\n",
    "\n",
    "print(\"Model in Epoch\", target_epoch)\n",
    "#テストデータで評価\n",
    "evaluate(testloader, epochmodel, loss_fn, optimizer)\n",
    "\n",
    "print('Forwarding Complete!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
